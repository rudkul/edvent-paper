{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0xSwPMHJGTN"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq torch==2.1 --progress-bar off\n",
        "!pip install -qqq transformers==4.34.1 --progress-bar off\n",
        "!pip install -qqq accelerate==0.23.0 --progress-bar off\n",
        "!pip install -qqq bitsandbytes==0.41.1 --progress-bar off\n",
        "!pip install -qqq llava-torch==1.1.1 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhJYdkzGJGp9"
      },
      "outputs": [],
      "source": [
        "!pip install h5py\n",
        "!pip install typing-extensions\n",
        "!pip install wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpLSJfPEJIRC",
        "outputId": "7da4b8b7-00c6-48d4-edf3-f5c10a5a1ffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-12-02 03:12:15,599] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "from io import BytesIO\n",
        "\n",
        "import requests\n",
        "import torch\n",
        "from llava.constants import DEFAULT_IMAGE_TOKEN, IMAGE_TOKEN_INDEX\n",
        "from llava.conversation import SeparatorStyle, conv_templates\n",
        "from llava.mm_utils import (\n",
        "    KeywordsStoppingCriteria,\n",
        "    get_model_name_from_path,\n",
        "    process_images,\n",
        "    tokenizer_image_token,\n",
        ")\n",
        "from llava.model.builder import load_pretrained_model\n",
        "from llava.utils import disable_torch_init\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQo5q8WhJKow"
      },
      "outputs": [],
      "source": [
        "disable_torch_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Dt7_kYfcJMdF",
        "outputId": "dd5725f6-f403-474e-a283-44b7294b856a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'llava-v1.5-13b-3GB'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL = \"4bit/llava-v1.5-13b-3GB\"\n",
        "model_name = get_model_name_from_path(MODEL)\n",
        "model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05Ds2Z2aJNzA"
      },
      "outputs": [],
      "source": [
        "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
        "    model_path=MODEL, model_base=None, model_name=model_name, load_4bit=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9IJpEScsKlGv"
      },
      "outputs": [],
      "source": [
        "CONV_MODE = \"llava_v0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OOR_aGLTGWoc"
      },
      "outputs": [],
      "source": [
        "! pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RrRxAOnMJALI"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FeZ9dzNRKLzz"
      },
      "outputs": [],
      "source": [
        "def process_image(image):\n",
        "    args = {\"image_aspect_ratio\": \"pad\"}\n",
        "    image_tensor = process_images([image], image_processor, args)\n",
        "    return image_tensor.to(model.device, dtype=torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LLmZ_2--KNzo"
      },
      "outputs": [],
      "source": [
        "def create_prompt(prompt: str):\n",
        "    conv = conv_templates[CONV_MODE].copy()\n",
        "    roles = conv.roles\n",
        "    prompt = DEFAULT_IMAGE_TOKEN + \"\\n\" + prompt\n",
        "    conv.append_message(roles[0], prompt)\n",
        "    conv.append_message(roles[1], None)\n",
        "    return conv.get_prompt(), conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CH5kh8lAKEic"
      },
      "outputs": [],
      "source": [
        "def ask_image(image: Image, prompt: str):\n",
        "    image_tensor = process_image(image)\n",
        "    prompt, conv = create_prompt(prompt)\n",
        "    input_ids = (\n",
        "        tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\")\n",
        "        .unsqueeze(0)\n",
        "        .to(model.device)\n",
        "    )\n",
        "\n",
        "    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
        "    stopping_criteria = KeywordsStoppingCriteria(\n",
        "        keywords=[stop_str], tokenizer=tokenizer, input_ids=input_ids\n",
        "    )\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        output_ids = model.generate(\n",
        "            input_ids,\n",
        "            images=image_tensor,\n",
        "            do_sample=True,\n",
        "            temperature=0.01,\n",
        "            max_new_tokens=512,\n",
        "            use_cache=True,\n",
        "            stopping_criteria=[stopping_criteria],\n",
        "        )\n",
        "    return tokenizer.decode(\n",
        "        output_ids[0, input_ids.shape[1] :], skip_special_tokens=True\n",
        "    ).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DPQj2DdNKKyM"
      },
      "outputs": [],
      "source": [
        "iface = gr.Interface(\n",
        "    fn=ask_image,\n",
        "    inputs=[gr.Image(), \"text\"],\n",
        "    outputs=\"text\",\n",
        "    live = False,\n",
        "    title = \"Edvent - Queryable Engine\",\n",
        "    flagging_options = [\"Good\", \"Bad\", \"Mid\"],\n",
        "    description = \"Upload an image and ask away!\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tPlFEL0o4wH4"
      },
      "outputs": [],
      "source": [
        "!pip install langchain gradio pypdf pandas matplotlib tiktoken textract transformers openai==0.28.1 faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1epwYs-D4wl_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import GPT2TokenizerFast\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NVAJWAoZ40GC"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2XvtDQzl41rH"
      },
      "outputs": [],
      "source": [
        "def process_pdf_and_query(pdf_content, query):\n",
        "  loader = PyPDFLoader(pdf_content)\n",
        "  pages = loader.load_and_split()\n",
        "  chunks = pages\n",
        "  embeddings = OpenAIEmbeddings()\n",
        "  db = FAISS.from_documents(chunks, embeddings)\n",
        "  chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "  docs = db.similarity_search(query)\n",
        "  result = chain.run(input_documents=docs, question=query)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T408etgC483y"
      },
      "outputs": [],
      "source": [
        "# Gradio interface\n",
        "inface = gr.Interface(\n",
        "    fn=process_pdf_and_query,\n",
        "    inputs=[gr.Textbox(label = \"Enter file path\"),gr.Textbox(label = \"Ask your questions\")],\n",
        "    outputs=\"text\",\n",
        "    live = False,\n",
        "    title = \"Edvent - Queryable Engine\",\n",
        "    flagging_options = [\"Good\", \"Bad\", \"Mid\"],\n",
        "    description = \"Upload your file and ask away!\"\n",
        ")\n",
        "\n",
        "inface.launch(share = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gnk108aPXC5"
      },
      "outputs": [],
      "source": [
        "# tts_demo = gr.Interface(\n",
        "#     fn = transcribe_english,\n",
        "#     inputs = \"text\",\n",
        "#     outputs = gr.File(),\n",
        "#     title=None,\n",
        "#     description=\"Upload your audio and generate the presentation in English!\",\n",
        "#     cache_examples=False\n",
        "# )\n",
        "# tts_demo1 = gr.Interface(\n",
        "#     fn = transcribe_kannada,\n",
        "#     inputs = \"text\",\n",
        "#     outputs = gr.File(),\n",
        "#     title=None,\n",
        "#     description=\"Upload your audio and generate the presentation in Kannada!\",\n",
        "#     cache_examples=False\n",
        "# )\n",
        "\n",
        "# tts_demo2 = gr.Interface(\n",
        "#     fn = transcribe_hindi,\n",
        "#     inputs = \"text\",\n",
        "#     outputs = gr.File(),\n",
        "#     title=None,\n",
        "#     description=\"Upload your audio and generate the presentation in Hindi!\",\n",
        "#     cache_examples=False\n",
        "# )\n",
        "\n",
        "inface = gr.Interface(\n",
        "    fn=process_pdf_and_query,\n",
        "    inputs=[gr.Textbox(label = \"Enter file path\"),gr.Textbox(label = \"Ask your questions\")],\n",
        "    outputs=\"text\",\n",
        "    live = False,\n",
        "    title = None,\n",
        "    # flagging_options = [\"Good\", \"Bad\", \"Mid\"],\n",
        "    description = \"Upload your file and ask away!\",\n",
        "     theme = gr.themes.Soft()\n",
        ")\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=ask_image,\n",
        "    inputs=[gr.Image(), \"text\"],\n",
        "    outputs=\"text\",\n",
        "    live = False,\n",
        "    title = None,\n",
        "    # flagging_options = [\"Good\", \"Bad\", \"Mid\"],\n",
        "    description = \"Upload an image and ask away!\",\n",
        "    theme = gr.themes.Soft()\n",
        ")\n",
        "\n",
        "demo = gr.TabbedInterface([inface, iface], [\"PDF Queryable Engine\",\"Image Queryable Engine\"], title=\"Edvent - Queryable Engine\", theme = gr.themes.Soft())\n",
        "demo.launch(share = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}